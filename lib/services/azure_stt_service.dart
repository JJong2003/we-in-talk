import 'dart:async'; // [ì¶”ê°€] íƒ€ì´ë¨¸ ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”
import 'dart:convert';
import 'dart:io';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';

class AzureSttService {
  final String subscriptionKey = dotenv.env['AZURE_SUBSCRIPTION_KEY'] ?? "";
  final String region = dotenv.env['AZURE_REGION'] ?? "koreacentral";

  final AudioRecorder _audioRecorder = AudioRecorder();
  String? _recordedFilePath;

  // ----------------------------------------------------------
  // â–¼ [ì¶”ê°€] ì¹¨ë¬µ ê°ì§€ë¥¼ ìœ„í•œ ë³€ìˆ˜ë“¤
  // ----------------------------------------------------------
  Timer? _amplitudeTimer; // ì†Œë¦¬ í¬ê¸° ì²´í¬ìš© íƒ€ì´ë¨¸
  Timer? _silenceTimer;   // ì¹¨ë¬µ ì§€ì† ì‹œê°„ ì²´í¬ìš© íƒ€ì´ë¨¸

  // ì¹¨ë¬µ ê¸°ì¤€ ë°ì‹œë²¨ (ì£¼ë³€ ì†ŒìŒì— ë”°ë¼ ì¡°ì ˆ: ë³´í†µ -30.0 ~ -40.0)
  // ì´ ê°’ë³´ë‹¤ ì†Œë¦¬ê°€ ì‘ìœ¼ë©´ 'ì¹¨ë¬µ'ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
  final double _silenceThreshold = -30.0;

  // ì¹¨ë¬µ ìœ ì§€ ì‹œê°„ (ì´ ì‹œê°„ ë™ì•ˆ ë§ì´ ì—†ìœ¼ë©´ ë…¹ìŒ ì¢…ë£Œ)
  final Duration _silenceDuration = const Duration(seconds: 1);

  // ì¹¨ë¬µ ê°ì§€ ì‹œ ì‹¤í–‰í•  ì½œë°± í•¨ìˆ˜
  Function()? onSilenceDetected;
  // ----------------------------------------------------------

  /// ë…¹ìŒ ì‹œì‘
  /// [onSilence]: ì¹¨ë¬µì´ ê°ì§€ë˜ì—ˆì„ ë•Œ ì‹¤í–‰í•  í•¨ìˆ˜ (ì„ íƒ ì‚¬í•­)
  Future<void> startRecording({Function()? onSilence}) async {
    // [ì¶”ê°€] ì½œë°± ë“±ë¡
    this.onSilenceDetected = onSilence;

    if (!await _audioRecorder.hasPermission()) {
      print("âŒ ë§ˆì´í¬ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    final Directory tempDir = await getTemporaryDirectory();
    _recordedFilePath = '${tempDir.path}/temp_audio.wav';

    const config = RecordConfig(
      encoder: AudioEncoder.wav,
      sampleRate: 16000,
      numChannels: 1,
    );

    final file = File(_recordedFilePath!);
    if (await file.exists()) {
      await file.delete();
    }

    await _audioRecorder.start(config, path: _recordedFilePath!);
    print("ğŸ¤ ë…¹ìŒ ì‹œì‘ (Path: $_recordedFilePath)");

    // [ì¶”ê°€] ì†Œë¦¬ í¬ê¸° ëª¨ë‹ˆí„°ë§ ì‹œì‘
    _startAmplitudeMonitoring();
  }

  // ----------------------------------------------------------
  // â–¼ [ì¶”ê°€] ì†Œë¦¬ í¬ê¸° ëª¨ë‹ˆí„°ë§ ë° ì¹¨ë¬µ ê°ì§€ ë¡œì§
  // ----------------------------------------------------------
  void _startAmplitudeMonitoring() {
    // 0.1ì´ˆë§ˆë‹¤ ì†Œë¦¬ í¬ê¸° ì²´í¬
    _amplitudeTimer = Timer.periodic(const Duration(milliseconds: 100), (timer) async {
      // ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆë©´ íƒ€ì´ë¨¸ ì¢…ë£Œ
      if (!await _audioRecorder.isRecording()) {
        timer.cancel();
        return;
      }

      // í˜„ì¬ ì†Œë¦¬ í¬ê¸°(dB) ê°€ì ¸ì˜¤ê¸°
      final amplitude = await _audioRecorder.getAmplitude();
      final currentDb = amplitude.current;

      // print("ğŸ”Š í˜„ì¬ ë°ì‹œë²¨: $currentDb"); // ë””ë²„ê¹…ì´ í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ

      if (currentDb < _silenceThreshold) {
        // ì†Œë¦¬ê°€ ê¸°ì¤€ì¹˜ë³´ë‹¤ ì‘ìŒ (ì¹¨ë¬µ ìƒíƒœ)
        // ì¹¨ë¬µ íƒ€ì´ë¨¸ê°€ ëŒê³  ìˆì§€ ì•Šë‹¤ë©´ ì‹œì‘
        if (_silenceTimer == null || !_silenceTimer!.isActive) {
          _silenceTimer = Timer(_silenceDuration, () {
            print("ğŸ¤« 1ì´ˆê°„ ì¹¨ë¬µ ê°ì§€ë¨! ë…¹ìŒ ìë™ ì¢…ë£Œ.");
            _stopMonitoring(); // ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
            if (onSilenceDetected != null) {
              onSilenceDetected!(); // ì™¸ë¶€(ChatView)ì— ì•Œë¦¼
            }
          });
        }
      } else {
        // ì†Œë¦¬ê°€ ê¸°ì¤€ì¹˜ë³´ë‹¤ í¼ (ë§í•˜ëŠ” ì¤‘)
        // ì¹¨ë¬µ íƒ€ì´ë¨¸ê°€ ëŒê³  ìˆì—ˆë‹¤ë©´ ì·¨ì†Œ (ë§ì„ ê³„ì† ì´ì–´ê°€ê³  ìˆìœ¼ë¯€ë¡œ)
        _silenceTimer?.cancel();
        _silenceTimer = null;
      }
    });
  }

  // ëª¨ë‹ˆí„°ë§ íƒ€ì´ë¨¸ ì •ë¦¬ í•¨ìˆ˜
  void _stopMonitoring() {
    _amplitudeTimer?.cancel();
    _silenceTimer?.cancel();
    _amplitudeTimer = null;
    _silenceTimer = null;
  }
  // ----------------------------------------------------------

  /// ë…¹ìŒ ì¤‘ì§€ ë° Azure ì „ì†¡
  Future<String?> stopRecordingAndGetText() async {
    // [ì¶”ê°€] ë…¹ìŒì´ ëë‚˜ë©´ ëª¨ë‹ˆí„°ë§ë„ ì¤‘ì§€
    _stopMonitoring();

    if (!await _audioRecorder.isRecording()) return null;

    final path = await _audioRecorder.stop();
    if (path == null) {
      print("âŒ ë…¹ìŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨");
      return null;
    }

    print("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ. Azureë¡œ ì „ì†¡ ì‹œì‘...");
    return await _sendToAzure(path);
  }

  Future<String?> _sendToAzure(String filePath) async {
    if (subscriptionKey.isEmpty) {
      print("âŒ .envì— AZURE_SUBSCRIPTION_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return "API í‚¤ ì˜¤ë¥˜";
    }
    final url = Uri.parse(
        "https://$region.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=ko-KR");

    try {
      final file = File(filePath);
      final bytes = await file.readAsBytes();

      final response = await http.post(
        url,
        headers: {
          "Ocp-Apim-Subscription-Key": subscriptionKey,
          "Content-Type": "audio/wav; codecs=audio/pcm; samplerate=16000",
          "Accept": "application/json",
        },
        body: bytes,
      );

      if (response.statusCode == 200) {
        final decoded = jsonDecode(utf8.decode(response.bodyBytes));
        if (decoded['RecognitionStatus'] == 'Success') {
          print("âœ… Azure ì¸ì‹ ì„±ê³µ: ${decoded['DisplayText']}");
          return decoded['DisplayText'];
        } else {
          print("âš ï¸ ì¸ì‹ ì‹¤íŒ¨ (Status: ${decoded['RecognitionStatus']})");
          return null;
        }
      } else {
        print("âŒ Azure ì„œë²„ ì˜¤ë¥˜: ${response.statusCode}");
        return null;
      }
    } catch (e) {
      print("âŒ í†µì‹  ì˜¤ë¥˜: $e");
      return null;
    }
  }

  void dispose() {
    // [ì¶”ê°€] ê°ì²´ ì†Œë©¸ ì‹œ íƒ€ì´ë¨¸ ì •ë¦¬
    _stopMonitoring();
    _audioRecorder.dispose();
  }
}